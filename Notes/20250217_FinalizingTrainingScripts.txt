âœ… Step 1: Understanding the Training Pipeline

    Reviewed the research paper to understand the Guess & Sketch method.
    Identified key scripts involved in training:
        train.py â†’ The main script handling training, dataset loading, and evaluation.
        arguments.py â†’ Defines all the training configurations and parameters.
        evaluation.py â†’ Handles model evaluation by testing predictions and tracking errors.
        ft_model.py â†’ Not used in the training process.

âœ… Step 2: Dataset Preparation

    Confirmed our training data source:
        Using JSON files (euler.json, unix_commands.json) from our earlier transpilation process.
        These contain aligned C code and assembly output for both ARM and RISC-V.
    Identified that we need both ARM â RISC-V & RISC-V â ARM translations.

âœ… Step 3: Understanding Model Loading & Training

    Identified the base model (facebook/bart-large) as the starting point.
    Confirmed fine-tuning instead of training from scratch.
    Understood the pipeline:
        Load the base model.
        Tokenize input-output pairs.
        Train with loss minimization.
        Evaluate using compilation and BLEU scores.

âœ… Step 4: Modifications & Improvements
ğŸ”¹ Modifications in evaluation.py

âœ”ï¸ Fixed architecture-specific compilation handling:

    Separated ARM and RISC-V compilations.
    Avoided overwriting files by appending _arm and _riscv to filenames.

âœ”ï¸ Tracked errors & successes separately for ARM & RISC-V:

    num_compiled_arm, num_tgt_compiled_arm, num_erroneous_lines_arm
    num_compiled_riscv, num_tgt_compiled_riscv, num_erroneous_lines_riscv
    num_em_arm, num_em_riscv for exact match tracking.

âœ”ï¸ Ensured correct compiler selection:

    Used:

    compilation_cmd = {
        'arm': 'aarch64-conda-linux-gnu-as',
        'riscv': 'riscv64-linux-gnu-as'
    }.get(tgt_lang, None)

âœ”ï¸ Structured evaluation results for better debugging:

    Stored JSON logs with predicted outputs and compiler errors.
    Returned all tracked variables using locals() for easier debugging.

âœ… Step 5: Next Steps

ğŸ”¹ Commit finalized changes to GitHub.
ğŸ”¹ Run a test training cycle with a small dataset.
ğŸ”¹ Verify outputs in ep{epoch}_eval_predictions.jsonl.
ğŸ”¹ Tune hyperparameters if necessary before full-scale training.
ğŸ”¥ Current Status:

âœ… Model training pipeline is understood.
âœ… Evaluation script is finalized & optimized.
âœ… Ready to start small-scale training before full deployment.
